{"cells":[{"cell_type":"code","execution_count":91,"metadata":{"executionInfo":{"elapsed":78,"status":"ok","timestamp":1739559335138,"user":{"displayName":"parthiv","userId":"04640313048952397858"},"user_tz":300},"id":"22gli6ZkIKDj"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim"]},{"cell_type":"code","source":["print(torch.cuda.is_available())\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hO7sS9VrrVZF","executionInfo":{"status":"ok","timestamp":1739559335248,"user_tz":300,"elapsed":6,"user":{"displayName":"parthiv","userId":"04640313048952397858"}},"outputId":"c4fe470a-1566-4437-8b26-3fb9c10d3478"},"execution_count":92,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n"]}]},{"cell_type":"code","execution_count":93,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1739559335248,"user":{"displayName":"parthiv","userId":"04640313048952397858"},"user_tz":300},"id":"_1WBdYCBIdG3"},"outputs":[],"source":["class PreContextRewardModel(nn.Module):\n","  def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n","    super(PreContextRewardModel, self).__init__()\n","    self.hidden_size = hidden_size\n","    self.num_layers = num_layers\n","\n","    # Embedding layer\n","    self.embedding = nn.Embedding(input_size, hidden_size)\n","\n","    # GRU layer\n","    self.gru = nn.GRU(hidden_size, hidden_size, num_layers, batch_first=True)\n","\n","    # Output layer\n","    self.fc = nn.Linear(hidden_size, output_size)\n","    # self.softmax = nn.Softmax(dim=1)\n","\n","  def forward(self, x, hidden):\n","    # Embed the input tokens\n","    x = self.embedding(x)\n","\n","    # Pass through GRU\n","    out, hidden = self.gru(x, hidden)\n","\n","    # Take the output of the last time step\n","    out = out[:, -1, :]\n","\n","    # Pass through fully connected layer\n","    out = self.fc(out)\n","\n","    # Apply softmax to get probabilities\n","    # out = self.softmax(out)\n","\n","    return out, hidden\n","\n","  def init_hidden(self, batch_size):\n","    return torch.zeros(self.num_layers, batch_size, self.hidden_size, device=device)"]},{"cell_type":"code","execution_count":94,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BpWwoN0cwjFB","executionInfo":{"status":"ok","timestamp":1739559335886,"user_tz":300,"elapsed":641,"user":{"displayName":"parthiv","userId":"04640313048952397858"}},"outputId":"09b20e33-f9bc-4be2-c581-b19c71dc3964"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":95,"metadata":{"id":"cFfGTCtYw2on","executionInfo":{"status":"ok","timestamp":1739559335886,"user_tz":300,"elapsed":4,"user":{"displayName":"parthiv","userId":"04640313048952397858"}}},"outputs":[],"source":["import json, os"]},{"cell_type":"code","execution_count":96,"metadata":{"id":"oZhKfk35xmhA","executionInfo":{"status":"ok","timestamp":1739559335887,"user_tz":300,"elapsed":4,"user":{"displayName":"parthiv","userId":"04640313048952397858"}}},"outputs":[],"source":["dataset_path = \"/content/drive/MyDrive/ECE570/data/\""]},{"cell_type":"code","execution_count":97,"metadata":{"id":"qkqeUOC0ySxN","executionInfo":{"status":"ok","timestamp":1739559335887,"user_tz":300,"elapsed":4,"user":{"displayName":"parthiv","userId":"04640313048952397858"}}},"outputs":[],"source":["def create_duet_pairs(parts):\n","  \"\"\"Create duet pairs from the four parts.\"\"\"\n","  duet_pairs = [\n","    (parts[\"soprano\"], parts[\"alto\"]),\n","    (parts[\"soprano\"], parts[\"tenor\"]),\n","    (parts[\"soprano\"], parts[\"bass\"]),\n","    (parts[\"alto\"], parts[\"tenor\"]),\n","    (parts[\"alto\"], parts[\"bass\"]),\n","    (parts[\"tenor\"], parts[\"bass\"]),\n","  ]\n","  return duet_pairs"]},{"cell_type":"code","execution_count":98,"metadata":{"id":"Xa21XTl8yo3p","executionInfo":{"status":"ok","timestamp":1739559335887,"user_tz":300,"elapsed":4,"user":{"displayName":"parthiv","userId":"04640313048952397858"}}},"outputs":[],"source":["def tokenize_part(part):\n","  \"\"\"Convert a part into a sequence of tokenized notes.\"\"\"\n","  tokens = []\n","  for n in part:\n","    if n == \"hold\":\n","      tokens.append(128)\n","    else:\n","      tokens.append(n)\n","  return tokens"]},{"cell_type":"code","execution_count":99,"metadata":{"id":"yLZo9Oiwy3Rf","executionInfo":{"status":"ok","timestamp":1739559337159,"user_tz":300,"elapsed":1275,"user":{"displayName":"parthiv","userId":"04640313048952397858"}}},"outputs":[],"source":["duet_data = []\n","for filename in os.listdir(dataset_path):\n","  if filename.endswith(\".json\"):  # Check if the file is a JSON file\n","    filepath = os.path.join(dataset_path, filename)\n","    with open(filepath, \"r\", encoding=\"utf-8\") as file:\n","      chorale_data = json.load(file)\n","      duet_pairs = create_duet_pairs(chorale_data)\n","      for human_part, machine_part in duet_pairs:\n","        human_tokens = tokenize_part(human_part)\n","        machine_tokens = tokenize_part(machine_part)\n","        duet_data.append((human_tokens, machine_tokens))"]},{"cell_type":"code","execution_count":100,"metadata":{"id":"0xqI_BHa0bXs","executionInfo":{"status":"ok","timestamp":1739559337159,"user_tz":300,"elapsed":3,"user":{"displayName":"parthiv","userId":"04640313048952397858"}}},"outputs":[],"source":["def prepare_training_data(duet_data, window_size=16):\n","  \"\"\"Prepare training data for the reward model.\"\"\"\n","  inputs = []\n","  targets = []\n","  for human_tokens, machine_tokens in duet_data:\n","    # Ensure both parts have the same length\n","    min_length = min(len(human_tokens), len(machine_tokens))\n","    human_tokens = human_tokens[:min_length]\n","    machine_tokens = machine_tokens[:min_length]\n","    # Create input-target pairs\n","    for i in range(window_size, min_length):\n","      input_seq = human_tokens[i-window_size:i]\n","      target = machine_tokens[i]\n","      inputs.append(input_seq)\n","      targets.append(target)\n","\n","  return inputs, targets"]},{"cell_type":"code","execution_count":106,"metadata":{"id":"ZGe2Khr218bv","executionInfo":{"status":"ok","timestamp":1739559666848,"user_tz":300,"elapsed":2108,"user":{"displayName":"parthiv","userId":"04640313048952397858"}}},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","# Prepare dataset\n","inputs, targets = prepare_training_data(duet_data)\n","\n","# Split into train and test sets (e.g., 80% train, 20% test)\n","train_inputs, test_inputs, train_targets, test_targets = train_test_split(\n","    inputs, targets, test_size=0.2, random_state=42\n",")\n"]},{"cell_type":"code","execution_count":107,"metadata":{"id":"aAECEuS41_Y3","executionInfo":{"status":"ok","timestamp":1739559666951,"user_tz":300,"elapsed":105,"user":{"displayName":"parthiv","userId":"04640313048952397858"}}},"outputs":[],"source":["# Hyperparameters\n","input_size = 129  # Number of unique tokens (MIDI pitches + rest)\n","hidden_size = 256\n","output_size = 129  # Same as input_size\n","num_layers = 2\n","learning_rate = 0.001\n","num_epochs = 10\n","batch_size = 32"]},{"cell_type":"code","execution_count":108,"metadata":{"id":"MEJJewE-2rE5","executionInfo":{"status":"ok","timestamp":1739559667140,"user_tz":300,"elapsed":191,"user":{"displayName":"parthiv","userId":"04640313048952397858"}}},"outputs":[],"source":["# Initialize model, loss, and optimizer\n","model = PreContextRewardModel(input_size, hidden_size, output_size, num_layers).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)"]},{"cell_type":"code","source":["train_inputs = torch.tensor(train_inputs, dtype=torch.long).to(device)\n","train_targets = torch.tensor(train_targets, dtype=torch.long).to(device)"],"metadata":{"id":"8yR1Pu0o1cor","executionInfo":{"status":"ok","timestamp":1739559667675,"user_tz":300,"elapsed":86,"user":{"displayName":"parthiv","userId":"04640313048952397858"}}},"execution_count":109,"outputs":[]},{"cell_type":"code","execution_count":110,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hHhugQ8o24WV","outputId":"84af1a63-85b2-428d-926c-1ecaa03bed40","executionInfo":{"status":"ok","timestamp":1739560081788,"user_tz":300,"elapsed":414115,"user":{"displayName":"parthiv","userId":"04640313048952397858"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Loss: 0.7925\n","Epoch [2/10], Loss: 0.7247\n","Epoch [3/10], Loss: 0.6686\n","Epoch [4/10], Loss: 0.6975\n","Epoch [5/10], Loss: 0.6685\n","Epoch [6/10], Loss: 0.7708\n","Epoch [7/10], Loss: 0.6706\n","Epoch [8/10], Loss: 0.7857\n","Epoch [9/10], Loss: 0.5735\n","Epoch [10/10], Loss: 0.5746\n"]}],"source":["# Training loop\n","for epoch in range(num_epochs):\n","  model.train()\n","\n","  for i in range(0, len(train_inputs), batch_size):\n","    # Get batch\n","    batch_inputs = train_inputs[i:i+batch_size]\n","    batch_targets = train_targets[i:i+batch_size]\n","    # Convert to tensors\n","    # batch_inputs = torch.tensor(batch_inputs, dtype=torch.long).to(device)\n","    # batch_targets = torch.tensor(batch_targets, dtype=torch.long).to(device)\n","\n","    # Dynamically initialize hidden state\n","    hidden = model.init_hidden(len(batch_inputs))\n","    # Forward pass\n","    hidden = hidden.detach()  # Detach hidden state to avoid backprop through time\n","    train_outputs, hidden = model(batch_inputs, hidden)\n","    # print(f\"Outputs shape: {train_outputs.shape}\")\n","    # print(f\"Batch targets shape: {batch_targets.shape}\")\n","    # print(train_outputs)\n","    # print(batch_targets)\n","\n","    # Compute loss\n","    loss = criterion(train_outputs, batch_targets)\n","    # Backward pass and optimize\n","    optimizer.zero_grad()\n","    loss.backward()\n","\n","    # Apply gradient clipping\n","    # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","\n","    optimizer.step()\n","\n","  print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n"]},{"cell_type":"code","execution_count":111,"metadata":{"id":"Y9OBwnDqKR5j","executionInfo":{"status":"ok","timestamp":1739560081788,"user_tz":300,"elapsed":28,"user":{"displayName":"parthiv","userId":"04640313048952397858"}}},"outputs":[],"source":["model_path = \"/content/drive/MyDrive/ECE570/models/pre_context_reward_model.pth\"\n","torch.save(model.state_dict(), model_path)"]},{"cell_type":"code","source":["test_inputs = torch.tensor(test_inputs, dtype=torch.long).to(device)\n","test_targets = torch.tensor(test_targets, dtype=torch.long).to(device)"],"metadata":{"id":"MyFpfmqa4b6g","executionInfo":{"status":"ok","timestamp":1739560449756,"user_tz":300,"elapsed":83,"user":{"displayName":"parthiv","userId":"04640313048952397858"}}},"execution_count":113,"outputs":[]},{"cell_type":"code","source":["def evaluate_model(model, test_inputs, test_targets):\n","    model.eval()  # Set to evaluation mode (disables dropout, etc.)\n","    with torch.no_grad():  # Disable gradient computation\n","        hidden = model.init_hidden(len(test_inputs))  # Adjust if needed\n","        test_outputs, _ = model(test_inputs, hidden)\n","\n","    # Compute loss\n","    loss = criterion(test_outputs, test_targets)\n","    print(f\"Test Loss: {loss.item()}\")\n","\n","    # Convert outputs to probabilities\n","    probs = torch.softmax(test_outputs, dim=1)\n","    predicted = torch.argmax(probs, dim=1)\n","\n","    # Compute accuracy\n","    accuracy = (predicted == test_targets).float().mean().item()\n","    print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n","\n","# Run evaluation\n","evaluate_model(model, test_inputs, test_targets)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WGNE9TClvDy-","executionInfo":{"status":"ok","timestamp":1739560452476,"user_tz":300,"elapsed":168,"user":{"displayName":"parthiv","userId":"04640313048952397858"}},"outputId":"b130ab55-08a4-4275-f70c-acad782eb839"},"execution_count":114,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Loss: 1.069266438484192\n","Test Accuracy: 72.42%\n"]}]}],"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyOmj65F1ScNqvjIzSoyY3HH"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}